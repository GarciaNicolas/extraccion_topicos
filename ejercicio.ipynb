{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('es_core_news_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lectura de archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtengo los nombres de los archivos csv\n",
    "files = os.listdir(\"./corpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for file in files:\n",
    "    with open(\"./corpus/\" + file, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "\n",
    "        #Elimino los saltos de linea\n",
    "        text = text.replace(\"\\n\", \" \")\n",
    "\n",
    "        #Agrego el archivo al conjunto de diccionarios\n",
    "        data.append({\"filename\": file, \"text\": text})\n",
    "\n",
    "#Creo el dataframe\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpieza de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Palabras que no aportan informacion\n",
    "ruido = [\"decir\",\"llamar\",\"hola\",\"pregunta\",\"buenas\",\"buenos\",\"dias\",\"dia\",\"tardes\",\"tarde\",\"noches\",\"gracias\",\"adios\",\"porfavor\",\"disculpe\",\"favor\",\"favor\",\"nombre\",\"bienvenido\",\"bienvenida\"]\n",
    "\n",
    "def es_token_relevante(token):\n",
    "    return not token.is_stop \\\n",
    "        and not token.is_punct \\\n",
    "        and not token.like_num \\\n",
    "        and not token.is_space \\\n",
    "        and (token.text not in ruido)\n",
    "\n",
    "def procesar_tokens(texto):\n",
    "    texto = texto.lower()\n",
    "\n",
    "    #Obtengo los tokens\n",
    "    doc = nlp(texto)\n",
    "\n",
    "    #Filtro y lematizo los tokens\n",
    "    tokens_relevantes = [token.lemma_ for token in doc if es_token_relevante(token)]\n",
    "\n",
    "    return tokens_relevantes\n",
    "\n",
    "df[\"corpus\"] = df[\"text\"].apply(procesar_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>34774-17-54-37.csv</td>\n",
       "      <td>Pregunta  Treinta y ocho</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>34780-09-04-00.csv</td>\n",
       "      <td>Pregunta  también .</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>34783-11-34-40.csv</td>\n",
       "      <td>Pregunta  Es el de dieciséis , siete , tres , ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>34794-16-58-19.csv</td>\n",
       "      <td>Pregunta  . , ya . Y</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>34806-12-20-06.csv</td>\n",
       "      <td>Pregunta  , no .</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>34806-18-35-33.csv</td>\n",
       "      <td>Pregunta  , ya , Sí , . , , sí , sí , . Ya y ....</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               filename                                               text  \\\n",
       "258  34774-17-54-37.csv                        Pregunta  Treinta y ocho      \n",
       "265  34780-09-04-00.csv                             Pregunta  también .      \n",
       "326  34783-11-34-40.csv  Pregunta  Es el de dieciséis , siete , tres , ...   \n",
       "442  34794-16-58-19.csv                            Pregunta  . , ya . Y      \n",
       "599  34806-12-20-06.csv                                Pregunta  , no .      \n",
       "609  34806-18-35-33.csv  Pregunta  , ya , Sí , . , , sí , sí , . Ya y ....   \n",
       "\n",
       "    corpus  \n",
       "258     []  \n",
       "265     []  \n",
       "326     []  \n",
       "442     []  \n",
       "599     []  \n",
       "609     []  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Filtro los corpus que no tienen tokens\n",
    "df[df['corpus'].apply(len) == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de limpiar los corpus, hay conversaciones que quedaron sin tokens. Eso es porque las únicas palabras en el llamado fueron stop words o ruido, es decir que se usaron palabras que no aportaron contexto a la conversación. Separo los corpus que tienen tópico de los que no y los etiqueto como 'Sin tópico'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separo los corpus que tienen tokens de los que no\n",
    "df_sin_topico = df[df['corpus'].apply(len) == 0]\n",
    "df = df[df['corpus'].apply(len) > 0]\n",
    "\n",
    "#Le asigno 'Sin topico' a los corpus que no tienen tokens\n",
    "df_sin_topico['topico'] = 'Sin topico'\n",
    "\n",
    "#Elimino la columna corpus\n",
    "df_sin_topico.drop(columns=['corpus'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def get_embedding(corpus):\n",
    "    \n",
    "    #Instancio el vectorizador adentro de la funcion para que no se guarde el vocabulario\n",
    "    vectorizer = TfidfVectorizer(stop_words=None)\n",
    "    embedding = vectorizer.fit_transform(corpus)\n",
    "    tokens = vectorizer.get_feature_names_out()\n",
    "\n",
    "    #Devuelvo una serie con el embedding y los tokens para poder asignarlos a las columnas del dataframe\n",
    "    return pd.Series([embedding, tokens], index=['embedding', 'corpus'])\n",
    "\n",
    "#Creo los embeddings del corpus\n",
    "df[['embedding', 'corpus']] = df['corpus'].apply(get_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracción de tópicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "from gensim.models import LdaModel, HdpModel\n",
    "from gensim.corpora.dictionary import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicol\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\decomposition\\_nmf.py:1710: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n",
      "C:\\Users\\nicol\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\decomposition\\_nmf.py:1710: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n",
      "C:\\Users\\nicol\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\decomposition\\_nmf.py:1710: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n",
      "C:\\Users\\nicol\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\decomposition\\_nmf.py:1710: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n",
      "C:\\Users\\nicol\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\decomposition\\_nmf.py:1710: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def get_topics(row, n_topics=3):\n",
    "\n",
    "    #Obtengo el embedding y los tokens de la fila\n",
    "    embedding = row['embedding']\n",
    "    tokens = row['corpus']\n",
    "\n",
    "    #Instancio el modelo NMF y lo entreno\n",
    "    nmf = NMF(n_components=n_topics, random_state=42)\n",
    "    nmf.fit(embedding)\n",
    "\n",
    "    #Obtengo los tópicos\n",
    "    top_words = nmf.components_.argsort()[:, -5:][0]\n",
    "    topicos = [tokens[i] for i in top_words]\n",
    "    \n",
    "    return topicos\n",
    "\n",
    "df['topico_nmf'] = df.apply(lambda x: get_topics(x, n_topics=3), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic(corpus):\n",
    "\n",
    "    #Creo un bolsa de palabras e inicializo el diccionario\n",
    "    dictionary = Dictionary([corpus])\n",
    "    bow = [dictionary.doc2bow(doc) for doc in [corpus]]\n",
    "\n",
    "    #Creo el modelo y extraigo los tópicos\n",
    "    model = HdpModel(corpus=bow, id2word=dictionary, random_state= 30)\n",
    "    topicos = model.print_topics()[0][1]\n",
    "\n",
    "    #Eliminos los coeficientes para dejar los tópicos limpios\n",
    "    topicos = topicos.replace('*', '+').replace('.','').split('+')\n",
    "    topicos = [topico.strip() for topico in topicos if not topico.strip().isnumeric()]\n",
    "\n",
    "    return topicos\n",
    "\n",
    "df['topico_hdp'] = df['corpus'].apply(get_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic(corpus):\n",
    "\n",
    "    #Creo un bolsa de palabras e inicializo el diccionario\n",
    "    dictionary = Dictionary([corpus])\n",
    "    bow = [dictionary.doc2bow(doc) for doc in [corpus]]\n",
    "\n",
    "    #Creo el modelo y extraigo los tópicos\n",
    "    model = LdaModel(corpus=bow, id2word=dictionary, random_state= 30, num_topics=5)\n",
    "    topicos = model.print_topics()[0][1]\n",
    "\n",
    "    #Eliminos los coeficientes para dejar los tópicos limpios\n",
    "    topicos = topicos.replace('*', '+').replace('.','').split('+')\n",
    "    topicos = [topico.strip() for topico in topicos if not topico.strip().isnumeric()]\n",
    "\n",
    "    return topicos\n",
    "\n",
    "df['topico_lda'] = df['corpus'].apply(get_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>corpus</th>\n",
       "      <th>embedding</th>\n",
       "      <th>topico_nmf</th>\n",
       "      <th>topico_hdp</th>\n",
       "      <th>topico_lda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34701-10-07-17.csv</td>\n",
       "      <td>Pregunta  Hola , mi nombre es Valeria . Discul...</td>\n",
       "      <td>[abrir, agradecer, arroba, asegurar, cadena, c...</td>\n",
       "      <td>(0, 73)\\t1.0\\n  (1, 29)\\t1.0\\n  (2, 39)\\t1.0...</td>\n",
       "      <td>[tía, josé, pedido, salmón, venir]</td>\n",
       "      <td>[necesitar, mirar, arroba, uva, agradecer, gua...</td>\n",
       "      <td>[\"rehacer\", \"agradecer\", \"dejar\", \"constanteme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34701-12-31-48.csv</td>\n",
       "      <td>Pregunta  Buenas tardes . punto Mi nombre es J...</td>\n",
       "      <td>[absolutamente, aparecer, asignar, atención, a...</td>\n",
       "      <td>(0, 35)\\t1.0\\n  (1, 21)\\t1.0\\n  (2, 17)\\t1.0...</td>\n",
       "      <td>[reservado, preocupar, ayudar, gutiérrez, pedido]</td>\n",
       "      <td>[recién, pedido, josé, indíqueme, ayudar, preo...</td>\n",
       "      <td>[\"meter\", \"buscar\", \"oir\", \"generar\", \"correo\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34701-12-57-22.csv</td>\n",
       "      <td>Pregunta  Hola . Buenas tardes . Habla con Mar...</td>\n",
       "      <td>[agradecer, azcárate, consulta, demorar, despa...</td>\n",
       "      <td>(0, 6)\\t1.0\\n  (1, 1)\\t1.0\\n  (2, 2)\\t1.0\\n ...</td>\n",
       "      <td>[maría, voisin, agradecer, mon, demorar]</td>\n",
       "      <td>[despacho, demorar, maría, agradecer, consulta...</td>\n",
       "      <td>[\"jueves\", \"azcárate\", \"maría\", \"demorar\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34701-13-27-47.csv</td>\n",
       "      <td>Pregunta  Buenas tardes , Francisco Moreno . ,...</td>\n",
       "      <td>[ahorrar, comunicar, correcto, desaparecer, em...</td>\n",
       "      <td>(0, 5)\\t1.0\\n  (1, 14)\\t1.0\\n  (2, 13)\\t1.0\\...</td>\n",
       "      <td>[llegar, yo, perder, correcto, pedido]</td>\n",
       "      <td>[página, francisco, eme, jota, mirar, comunica...</td>\n",
       "      <td>[\"ir\", \"pasar\", \"comunicar\", \"francisco\", \"des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34701-13-56-30.csv</td>\n",
       "      <td>Pregunta  al final . Hola , buenas tardes con ...</td>\n",
       "      <td>[ana, aparecer, arepa, bolsa, comprar, corrobo...</td>\n",
       "      <td>(0, 11)\\t1.0\\n  (1, 14)\\t1.0\\n  (2, 24)\\t1.0...</td>\n",
       "      <td>[precio, máquina, oferta, página, aparecer]</td>\n",
       "      <td>[retiro, mirar, bolsa, mandar, querer, aparece...</td>\n",
       "      <td>[\"dirección\", \"máquina\", \"retiro\", \"aparecer\",...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>34809-12-21-48.csv</td>\n",
       "      <td>Pregunta  barba . Buenas tardes . . tengo una ...</td>\n",
       "      <td>[atender, ayer, barba, cambiar, cancelar, celu...</td>\n",
       "      <td>(0, 2)\\t1.0\\n  (1, 6)\\t1.0\\n  (2, 20)\\t1.0\\n...</td>\n",
       "      <td>[pedido, página, salir, decir, llegar]</td>\n",
       "      <td>[pedido, corresponder, venir, ver, consulta, m...</td>\n",
       "      <td>[\"sustituir\", \"llegar\", \"celular\", \"mandar\", \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>34809-12-37-51.csv</td>\n",
       "      <td>Pregunta  Hola . Buenos días . Mi nombre es Pa...</td>\n",
       "      <td>[abrir, acabar, aceptar, amable, bonito, cajer...</td>\n",
       "      <td>(0, 36)\\t1.0\\n  (1, 46)\\t1.0\\n  (2, 12)\\t1.0...</td>\n",
       "      <td>[perdón, amable, confirmar, despacho, querer]</td>\n",
       "      <td>[error, duplicar, promoción, compra, proceso, ...</td>\n",
       "      <td>[\"despacho\", \"información\", \"cajera\", \"ingresa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>34809-12-42-09.csv</td>\n",
       "      <td>Pregunta  Buenas tardes . Bienvenido . . mi no...</td>\n",
       "      <td>[anotar, anulación, anulado, anular, aparecer,...</td>\n",
       "      <td>(0, 38)\\t1.0\\n  (1, 56)\\t1.0\\n  (2, 57)\\t1.0...</td>\n",
       "      <td>[tarjeta, sistema, perfecto, entrega, pedido]</td>\n",
       "      <td>[solicitar, inmediatamente, lunes, boleta, mai...</td>\n",
       "      <td>[\"problema\", \"par\", \"opción\", \"reclamo\", \"rela...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>34809-12-45-28.csv</td>\n",
       "      <td>Pregunta  . Mira , tengo una pura . Es una com...</td>\n",
       "      <td>[abrir, acceso, actualizar, alguien, alternati...</td>\n",
       "      <td>(0, 52)\\t1.0\\n  (1, 77)\\t1.0\\n  (2, 18)\\t1.0...</td>\n",
       "      <td>[unidad, exactamente, mencionar, compra, produ...</td>\n",
       "      <td>[mastercard, llamada, acceso, plástico, abrir,...</td>\n",
       "      <td>[\"solitar\", \"incidencia\", \"oficial\", \"pedir\", ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>34809-13-53-07.csv</td>\n",
       "      <td>Pregunta  Buenas tardes . Bienvenida . Mi nomb...</td>\n",
       "      <td>[abrir, aderezo, aparecer, asegurar, ayer, ayu...</td>\n",
       "      <td>(0, 32)\\t1.0\\n  (1, 39)\\t1.0\\n  (2, 40)\\t1.0...</td>\n",
       "      <td>[pedido, número, país, compra, producto]</td>\n",
       "      <td>[indíqueme, hablar, oliva, sustituir, dijiste,...</td>\n",
       "      <td>[\"opción\", \"domicilio\", \"terminado\", \"devoluci...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>634 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               filename                                               text  \\\n",
       "0    34701-10-07-17.csv  Pregunta  Hola , mi nombre es Valeria . Discul...   \n",
       "1    34701-12-31-48.csv  Pregunta  Buenas tardes . punto Mi nombre es J...   \n",
       "2    34701-12-57-22.csv  Pregunta  Hola . Buenas tardes . Habla con Mar...   \n",
       "3    34701-13-27-47.csv  Pregunta  Buenas tardes , Francisco Moreno . ,...   \n",
       "4    34701-13-56-30.csv  Pregunta  al final . Hola , buenas tardes con ...   \n",
       "..                  ...                                                ...   \n",
       "635  34809-12-21-48.csv  Pregunta  barba . Buenas tardes . . tengo una ...   \n",
       "636  34809-12-37-51.csv  Pregunta  Hola . Buenos días . Mi nombre es Pa...   \n",
       "637  34809-12-42-09.csv  Pregunta  Buenas tardes . Bienvenido . . mi no...   \n",
       "638  34809-12-45-28.csv  Pregunta  . Mira , tengo una pura . Es una com...   \n",
       "639  34809-13-53-07.csv  Pregunta  Buenas tardes . Bienvenida . Mi nomb...   \n",
       "\n",
       "                                                corpus  \\\n",
       "0    [abrir, agradecer, arroba, asegurar, cadena, c...   \n",
       "1    [absolutamente, aparecer, asignar, atención, a...   \n",
       "2    [agradecer, azcárate, consulta, demorar, despa...   \n",
       "3    [ahorrar, comunicar, correcto, desaparecer, em...   \n",
       "4    [ana, aparecer, arepa, bolsa, comprar, corrobo...   \n",
       "..                                                 ...   \n",
       "635  [atender, ayer, barba, cambiar, cancelar, celu...   \n",
       "636  [abrir, acabar, aceptar, amable, bonito, cajer...   \n",
       "637  [anotar, anulación, anulado, anular, aparecer,...   \n",
       "638  [abrir, acceso, actualizar, alguien, alternati...   \n",
       "639  [abrir, aderezo, aparecer, asegurar, ayer, ayu...   \n",
       "\n",
       "                                             embedding  \\\n",
       "0      (0, 73)\\t1.0\\n  (1, 29)\\t1.0\\n  (2, 39)\\t1.0...   \n",
       "1      (0, 35)\\t1.0\\n  (1, 21)\\t1.0\\n  (2, 17)\\t1.0...   \n",
       "2      (0, 6)\\t1.0\\n  (1, 1)\\t1.0\\n  (2, 2)\\t1.0\\n ...   \n",
       "3      (0, 5)\\t1.0\\n  (1, 14)\\t1.0\\n  (2, 13)\\t1.0\\...   \n",
       "4      (0, 11)\\t1.0\\n  (1, 14)\\t1.0\\n  (2, 24)\\t1.0...   \n",
       "..                                                 ...   \n",
       "635    (0, 2)\\t1.0\\n  (1, 6)\\t1.0\\n  (2, 20)\\t1.0\\n...   \n",
       "636    (0, 36)\\t1.0\\n  (1, 46)\\t1.0\\n  (2, 12)\\t1.0...   \n",
       "637    (0, 38)\\t1.0\\n  (1, 56)\\t1.0\\n  (2, 57)\\t1.0...   \n",
       "638    (0, 52)\\t1.0\\n  (1, 77)\\t1.0\\n  (2, 18)\\t1.0...   \n",
       "639    (0, 32)\\t1.0\\n  (1, 39)\\t1.0\\n  (2, 40)\\t1.0...   \n",
       "\n",
       "                                            topico_nmf  \\\n",
       "0                   [tía, josé, pedido, salmón, venir]   \n",
       "1    [reservado, preocupar, ayudar, gutiérrez, pedido]   \n",
       "2             [maría, voisin, agradecer, mon, demorar]   \n",
       "3               [llegar, yo, perder, correcto, pedido]   \n",
       "4          [precio, máquina, oferta, página, aparecer]   \n",
       "..                                                 ...   \n",
       "635             [pedido, página, salir, decir, llegar]   \n",
       "636      [perdón, amable, confirmar, despacho, querer]   \n",
       "637      [tarjeta, sistema, perfecto, entrega, pedido]   \n",
       "638  [unidad, exactamente, mencionar, compra, produ...   \n",
       "639           [pedido, número, país, compra, producto]   \n",
       "\n",
       "                                            topico_hdp  \\\n",
       "0    [necesitar, mirar, arroba, uva, agradecer, gua...   \n",
       "1    [recién, pedido, josé, indíqueme, ayudar, preo...   \n",
       "2    [despacho, demorar, maría, agradecer, consulta...   \n",
       "3    [página, francisco, eme, jota, mirar, comunica...   \n",
       "4    [retiro, mirar, bolsa, mandar, querer, aparece...   \n",
       "..                                                 ...   \n",
       "635  [pedido, corresponder, venir, ver, consulta, m...   \n",
       "636  [error, duplicar, promoción, compra, proceso, ...   \n",
       "637  [solicitar, inmediatamente, lunes, boleta, mai...   \n",
       "638  [mastercard, llamada, acceso, plástico, abrir,...   \n",
       "639  [indíqueme, hablar, oliva, sustituir, dijiste,...   \n",
       "\n",
       "                                            topico_lda  \n",
       "0    [\"rehacer\", \"agradecer\", \"dejar\", \"constanteme...  \n",
       "1    [\"meter\", \"buscar\", \"oir\", \"generar\", \"correo\"...  \n",
       "2    [\"jueves\", \"azcárate\", \"maría\", \"demorar\", \"mo...  \n",
       "3    [\"ir\", \"pasar\", \"comunicar\", \"francisco\", \"des...  \n",
       "4    [\"dirección\", \"máquina\", \"retiro\", \"aparecer\",...  \n",
       "..                                                 ...  \n",
       "635  [\"sustituir\", \"llegar\", \"celular\", \"mandar\", \"...  \n",
       "636  [\"despacho\", \"información\", \"cajera\", \"ingresa...  \n",
       "637  [\"problema\", \"par\", \"opción\", \"reclamo\", \"rela...  \n",
       "638  [\"solitar\", \"incidencia\", \"oficial\", \"pedir\", ...  \n",
       "639  [\"opción\", \"domicilio\", \"terminado\", \"devoluci...  \n",
       "\n",
       "[634 rows x 7 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No hay una forma muy directa para comparar el desempeño de estos 3 algoritmos porque usan 3 encares distintos. Non-negative Matrix Fatorization (NMF) usa algebra lineal para la descomposición de tópicos, Hierarchical Dirichlet Process (HDP) busca agrupar un conjunto de datos según su distribución, y Latent Dirichlet Allocation (LDA) calcula las probabilidades de que una palabra pertenezca a un conjunto. A su vez son 640 casos distintos (modelos distintos, no relacionados), lo cual dificulta  un poco el análisis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de evaluar los distintos modelos, viendo que conjunto de palabras representaban mejor a la conversación, decidí que el mejor modelo fue el Hierarchical Dirichlet Process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elimino las columnas que no voy a usar más\n",
    "df.drop(columns=['embedding', 'corpus','topico_nmf','topico_lda'], inplace=True)\n",
    "\n",
    "#Renombro la columna de tópicos\n",
    "df.rename(columns={'topico_hdp':'topico'}, inplace=True)\n",
    "\n",
    "#Concateno los corpus que no tienen tópico con los que si\n",
    "df = pd.concat([df, df_sin_topico])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>topico</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34701-10-07-17.csv</td>\n",
       "      <td>Pregunta  Hola , mi nombre es Valeria . Discul...</td>\n",
       "      <td>[necesitar, mirar, arroba, uva, agradecer, gua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34701-12-31-48.csv</td>\n",
       "      <td>Pregunta  Buenas tardes . punto Mi nombre es J...</td>\n",
       "      <td>[recién, pedido, josé, indíqueme, ayudar, preo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34701-12-57-22.csv</td>\n",
       "      <td>Pregunta  Hola . Buenas tardes . Habla con Mar...</td>\n",
       "      <td>[despacho, demorar, maría, agradecer, consulta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34701-13-27-47.csv</td>\n",
       "      <td>Pregunta  Buenas tardes , Francisco Moreno . ,...</td>\n",
       "      <td>[página, francisco, eme, jota, mirar, comunica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34701-13-56-30.csv</td>\n",
       "      <td>Pregunta  al final . Hola , buenas tardes con ...</td>\n",
       "      <td>[retiro, mirar, bolsa, mandar, querer, aparece...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>34809-12-21-48.csv</td>\n",
       "      <td>Pregunta  barba . Buenas tardes . . tengo una ...</td>\n",
       "      <td>[pedido, corresponder, venir, ver, consulta, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>34809-12-37-51.csv</td>\n",
       "      <td>Pregunta  Hola . Buenos días . Mi nombre es Pa...</td>\n",
       "      <td>[error, duplicar, promoción, compra, proceso, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>34809-12-42-09.csv</td>\n",
       "      <td>Pregunta  Buenas tardes . Bienvenido . . mi no...</td>\n",
       "      <td>[solicitar, inmediatamente, lunes, boleta, mai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>34809-12-45-28.csv</td>\n",
       "      <td>Pregunta  . Mira , tengo una pura . Es una com...</td>\n",
       "      <td>[mastercard, llamada, acceso, plástico, abrir,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>34809-13-53-07.csv</td>\n",
       "      <td>Pregunta  Buenas tardes . Bienvenida . Mi nomb...</td>\n",
       "      <td>[indíqueme, hablar, oliva, sustituir, dijiste,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>634 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               filename                                               text  \\\n",
       "0    34701-10-07-17.csv  Pregunta  Hola , mi nombre es Valeria . Discul...   \n",
       "1    34701-12-31-48.csv  Pregunta  Buenas tardes . punto Mi nombre es J...   \n",
       "2    34701-12-57-22.csv  Pregunta  Hola . Buenas tardes . Habla con Mar...   \n",
       "3    34701-13-27-47.csv  Pregunta  Buenas tardes , Francisco Moreno . ,...   \n",
       "4    34701-13-56-30.csv  Pregunta  al final . Hola , buenas tardes con ...   \n",
       "..                  ...                                                ...   \n",
       "635  34809-12-21-48.csv  Pregunta  barba . Buenas tardes . . tengo una ...   \n",
       "636  34809-12-37-51.csv  Pregunta  Hola . Buenos días . Mi nombre es Pa...   \n",
       "637  34809-12-42-09.csv  Pregunta  Buenas tardes . Bienvenido . . mi no...   \n",
       "638  34809-12-45-28.csv  Pregunta  . Mira , tengo una pura . Es una com...   \n",
       "639  34809-13-53-07.csv  Pregunta  Buenas tardes . Bienvenida . Mi nomb...   \n",
       "\n",
       "                                                topico  \n",
       "0    [necesitar, mirar, arroba, uva, agradecer, gua...  \n",
       "1    [recién, pedido, josé, indíqueme, ayudar, preo...  \n",
       "2    [despacho, demorar, maría, agradecer, consulta...  \n",
       "3    [página, francisco, eme, jota, mirar, comunica...  \n",
       "4    [retiro, mirar, bolsa, mandar, querer, aparece...  \n",
       "..                                                 ...  \n",
       "635  [pedido, corresponder, venir, ver, consulta, m...  \n",
       "636  [error, duplicar, promoción, compra, proceso, ...  \n",
       "637  [solicitar, inmediatamente, lunes, boleta, mai...  \n",
       "638  [mastercard, llamada, acceso, plástico, abrir,...  \n",
       "639  [indíqueme, hablar, oliva, sustituir, dijiste,...  \n",
       "\n",
       "[634 rows x 3 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
